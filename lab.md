---
layout: page
title: ""
---

![lab](https://user-images.githubusercontent.com/87885251/236451289-9b16c833-7a27-4e43-9092-37e78b42d428.png)

---

## 写在前面：
首先感谢你对HACI小组的关注。我们欢迎计算机、电子、心理学、教育学等不同领域的本科生、硕士、博士合作伙伴。
我们会尽力打造一个融洽、互助、充满新鲜感的学习科研环境。如果你有类似的兴趣，请认真看至末尾（有预习作业哦）。

First of all, thank you for your interest in the HACI team. We welcome undergraduate, master's, and doctoral partners from various fields such as computer science, electronics, psychology, and education.
We will do our best to create a harmonious, supportive, and exciting learning and research environment. If you share a similar interest, please read carefully until the end (there is pre-work to be done).

## Research Interests
<img width="1414" alt="ResearchInterests" src="https://user-images.githubusercontent.com/87885251/236441656-f53405a0-7f9a-461f-8202-0f7aed648694.png">

We mainly focus on emotion+ research topics through the utilization of deep learning methods. Our research architecture is depicted in the figure above.

Different from traditional research methods, we combine **cognitive science**, **psychology**, **robotics** and **artificial intelligence** related technologies to explore from theoretical level to practical application level. 
In particular, we focuses on the use of deep learning models to assess multi-modal data, such as speech information, visual information, text information, for the purpose of analyzing human emotions, comprehending behavior, and generating affective expression. Additionally, by taking psychology and cognitive science into account, we also attempt to optimize the interaction strategy. 


## The Gole

The human-agent symbiotic society is coming! We can expect to see more emotionally intelligent agents that can interact with humans in a more natural and empathetic way. These agents will be able to interpret and respond to human emotions, making them more useful in a variety of contexts, such as healthcare, education, and rapport building. As for the gole, we are going to:

### Improved Human-Computer Interaction: 
Affective computing can improve the interaction between humans and machines by making the experience more natural and intuitive. Emotionally intelligent machines can detect and respond to a user's emotional state, making the interaction more personalized and engaging.

### Enhanced Mental Health: 
Affective computing can help healthcare professionals to monitor the emotional state of patients and develop personalized treatment plans. It can also help individuals with mental health disorders to manage their condition by providing real-time feedback and support.


## Preworks to Whom Wants to Join HACI

### Prework 1:
Go through my publication list and choose some paper to read that interests you.
Please conduct a survey on the topics of affective computing, human-robot interaction (or human-agent interaction), and cognitive science, so as to have some basic knowledge.

### Prework 2:
Imagine a scenario of a future society where human-machine symbiosis is prevalent, and propose a technology application related to emotions.

### Prework 3:
Please specify the technologies required to realize the scenario you proposed.

----
如果你完成到了这里，那你大概率是和我们有一致兴趣的人。请你将prework2和3总结为500字短文，并上交给我。我会分享给你学习资料，开始你的科研活动！

If you have reached here, then you are most likely someone who shares our interests. Please summarize Prework 2 and 3 into a 500-word essay and submit it to me. I will share with you the relevant learning materials and start the research activity!


## 写在最后：
探索的过程都是充满困难的，请各位伙伴们保持主动，迎难而上，享受突破困难的那一瞬间，肾上腺素给你带来的兴奋和喜悦感！

The process of exploration is always full of difficulties. We encourage our colleagues to be proactive, face challenges, and enjoy the moment when they overcome difficulties. The excitement and joy that adrenaline brings will be an amazing experience.

---

# People
### PhD student

<table>
  <tr>
    <td> <img src="https://github.com/CZ26/CZ-HP/assets/87885251/8ad239c7-322c-4e1a-b2b1-00869d692289" width="150" height="150" /> <br/> <em>Shihab Baten Md<br/>@ Osaka University</em> </td>
      <td> <img src="https://github.com/CZ26/CZ-HP/assets/87885251/0d740b33-f98e-49ea-a9e0-0ea002bf895f" width="150" height="150" /> <br/> <em>Ayush Gupta<br/>@ Osaka University</em> </td>
    </tr> 
</table>

### Master student
<table>
  <tr>
    <td> <img src="https://github.com/CZ26/CZ-HP/assets/87885251/538e86b6-c28a-4ef4-99f8-3b74a05236ba" width="150" height="150" /> <br/> <em>Yan Fu<br/>@ Northeastern University</em> </td>
    <td> <img src="https://github.com/CZ26/CZ-HP/assets/87885251/4fc04bf3-151a-45c1-bd92-9eebddd8a1ee" width="150" height="150" /> <br/> <em>Xiaoai Wang<br/>@ Northeastern University</em> </td>
  </tr> 
  <tr>  
    <td> <img src="https://github.com/CZ26/CZ-HP/assets/87885251/187c5a95-e77e-4ca1-9792-639a02442ed6" width="150" height="150" /> <br/> <em>Yinghao Liu<br/>@ Northeastern University</em> </td>
    <td> <img src="https://github.com/CZ26/CZ-HP/assets/87885251/0d0f7c1a-f72b-4ba3-a823-8f6bd9cbeefb" width="150" height="150" /> <br/> <em>Yikai Su<br/>@ Northeastern University</em> </td>
    <td> <img src="https://github.com/CZ26/CZ-HP/assets/87885251/d16bf85b-ccbe-4aaa-b2f4-57033c335db0" width="150" height="150" /> <br/> <em>Kaifeng Su<br/>@ Northeastern University</em> </td>
  </tr> 
</table>

### Undergraduate student

<table>
  <tr>
    <td> <img src="" width="150" height="150" /> <br/> <em>Huizu Lin<br/>@ SSTC-NEU</em> </td>
    <td> <img src="https://github.com/CZ26/CZ-HP/assets/87885251/ec6c8fef-9d33-480d-97d0-e58cc3c5a63a" width="150" height="150" /> <br/> <em>Yaohang Li<br/>@ SSTC-NEU & UTS</em> </td>
    <td> <img src="https://github.com/CZ26/CZ-HP/assets/87885251/9f0040f4-b707-4e09-bbbe-b47586edd999" width="150" height="150" /> <br/> <em>Zihan Li<br/>@ SSTC-NEU</em> </td>
    <td> <img src="https://github.com/CZ26/CZ-HP/assets/87885251/1361793a-eb43-46cb-ab98-47991ce4179e" width="150" height="150" /> <br/> <em>Yibo Peng<br/>@ SSTC-NEU</em> </td>
  </tr> 
  <tr>
    <td> <img src="https://github.com/CZ26/CZ-HP/assets/87885251/10027025-9434-4a86-af29-5b8d9ef1e466" width="150" height="150" /> <br/> <em>Xiniang Wang<br/>@ SSTC-NEU</em> </td>
    <td> <img src="https://github.com/CZ26/CZ-HP/assets/87885251/1e18436f-c60e-43b1-b268-73ddfc8c35de" width="150" height="150" /> <br/> <em>Yiming Yang<br/>@ SSTC-NEU</em> </td>
    <td> <img src="" width="150" height="150" /> <br/> <em>Songyang Wang<br/>@ SSTC-NEU</em> </td>
    <td> <img src="" width="150" height="150" /> <br/> <em>Ruiding Huang<br/>@ SSTC-NEU</em> </td>
  </tr>
  <tr>
    <td> <img src="https://github.com/CZ26/CZ-HP/assets/87885251/71bc8378-5793-4455-8d09-52d8971839e8" width="150" height="150" /> <br/> <em>Yunzhao Fu<br/>@ SSTC-NEU</em> </td>
  </tr> 
</table>

### Research Partner
   
<table>
  <tr>
    <td> <img src="https://github.com/CZ26/CZ-HP/assets/87885251/bfa7790d-5e71-4748-a406-1386bee9d04e" width="300" height="150" /> <br/> <a href="https://www.irl.sys.es.osaka-u.ac.jp/">IRL<br/>@Osaka University</a> </td>
     <td> <img src="https://github.com/CZ26/CZ-HP/assets/87885251/91a64529-ee83-435f-ab24-fc2979ffd8cf" width="400" height="150" /> <br/> <a href="https://grp.riken.jp/">GRP<br/>@RIKEN</a> </td>
    <td> <img src="https://github.com/CZ26/CZ-HP/assets/87885251/3c307cb4-f0b2-4402-aa35-967d7580abc8" width="150" height="150" /> <br/> <em>Add Lab<br/></em> </td>
   </tr> 
</table>
